#!/usr/bin/env python3

import os
import sys
import yaml
from utils import *

MODELS = ['clock', 'noClock']
RUNS = [f'{i+1:04d}' for i in range(config['cellcoal']['no_rep'])]

scheduler = config.get('scheduler', None)


if isinstance(config['mrbayes']['ngen'], (int, float)):
    config['mrbayes']['ngen'] = [config['mrbayes']['ngen']]
out_dir = get_out_dir(config)


def get_mrbayes_hpc_runtime(steps):
    steps_int = int(steps)
    if steps_int <= 1E6:
        runtime = '04:00:00'
    elif steps_int <= 5E6:
        runtime = '08:00:00'
    elif steps_int <= 10E6:
        runtime = '24:00:00'
    elif steps_int <= 20E6:
        runtime = '48:00:00'
    elif steps_int <= 60E6:
        runtime = '64:00:00'
    elif steps_int <= 80E6:
        runtime = '80:00:00'
    else:
        runtime = '96:00:00'
        
    if scheduler == 'lsf':
        return runtime[:-3]
    else:
        return runtime


def get_final_files(wildcards):
    files = []
    if config['cellcoal'].get('output', {}).get('true_haplotypes', False):
        files += [os.path.join(out_dir, 'true_haplotypes_dir', f'true_vcf.{i}') 
            for i in RUNS]
    if config.get('mrbayes', {}).get('run', False):
        files.append(os.path.join(out_dir, 'mrbayes.clock_test_summary.tsv'))
    if config.get('paup', {}).get('run', False):
        files.append(os.path.join(out_dir, 'paup.clock_test_summary.tsv'))
    if config.get('scite', {}).get('run', False):
        files += [os.path.join(out_dir, 'scite_dir', f'scite_tree.{i}_ml0.newick') 
            for i in RUNS]
    if config.get('sieve', {}).get('run', False):
        files.append(os.path.join(out_dir, 'sieve.clock_test_summary.tsv'))

    return files


rule all:
    input:
        get_final_files
        
            
rule create_cellcoal_config:
    output:
        cellcoal = 'cellcoal_parameters',
        snakemake ='snakemake_config.yaml',
    params:
        template = config['cellcoal'] \
            .get('parameter', 'cellcoal_parameters.template'),
    resources:
        mem_mb = 1024
    run:
        cc_config = get_cellcoal_config(config, params.template, out_dir)
        with open(output.cellcoal, 'w') as f:
            f.write(cc_config)
        with open(output.snakemake, 'w') as f_yaml:
            yaml.dump(config, f_yaml)


rule run_cellcoal:
    input:
        cellcoal = 'cellcoal_parameters',
        snakemake ='snakemake_config.yaml',
    output:
        expand(os.path.join(out_dir, 'vcf_dir', 'vcf.{run}'), run=RUNS),
    resources:
        mem_mb = 32768 * (1 + config['cellcoal'].get('no_rep', 10) // 500)
    params:
        exe = config['cellcoal']['exe'],
    shell:
        'mkdir -p {out_dir} && {params.exe} -F{input} > {out_dir}/log && '
        'mv {input.cellcoal} {out_dir}/config_cellcoal &&'
        'mv {input.snakemake} {out_dir}/config_snakemake'


rule get_true_GT:
    input:
        os.path.join(out_dir, 'vcf_dir', 'vcf.{run}')
    output:
        os.path.join(out_dir, 'true_haplotypes_dir', 'true_vcf.{run}')
    resources:
        mem_mb = 4096
    run:
        haplotypes_to_vcf(input[0], output[0])


if config.get('monovar', {}).get('run', False):
    vcf_in_file = 'vcf.{run}.monovar.vcf'
else:
    vcf_in_file = 'vcf.{run}'

rule vcf_to_nex:
    input:
        os.path.join(out_dir, 'vcf_dir', vcf_in_file)
    output:
        expand(os.path.join(out_dir, 'nxs_dir', 'nxs.{{run}}.{{steps}}.{model}'),
            model=MODELS)
    resources:
        mem_mb = 1024
    params:
        ss = config.get('mrbayes', {}).get('ss', False),
        tree = config.get('mrbayes', {}).get('use_tree', False) \
            or config.get('paup', {}).get('run', False),
        full_GT = config.get('paup', {}).get('full_GT', False),
        learn_tree = config.get('paup', {}).get('learn_tree', False),
        min_DP = config['cellcoal'].get('SNP_filter', {}).get('depth', 1),
        min_GQ = config['cellcoal'].get('SNP_filter', {}).get('quality', 1),
    run:
        vcf_to_nex(input[0], output, wildcards.steps,
            ss_flag=params.ss, tree=params.tree, learn_tree=params.learn_tree,
            full_GT=params.full_GT, minDP=params.min_DP, minGQ=params.min_GQ)


# ------------------------------- MONOVAR --------------------------------------

rule vcf_to_mpileup:
    input:
        os.path.join(out_dir, 'vcf_dir', 'vcf.{run}')
    output:
        pileup = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.mpileup'),
        samples = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleNames.txt'),
        s_types = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleTypes.txt')
    resources:
        mem_mb = 4096
    run:
        vcf_to_pileup(input[0], output.pileup, output.samples)


rule run_monovar:
    input:
        pileup = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.mpileup'),
        samples = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleNames.txt')
    output:
        os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.monovar.vcf')
    threads: 2
    resources:
        mem_mb = 4096 if scheduler == 'lsf' else 2 * 4096
    conda:
        'envs/monovar.yaml'
    envmodules:
        'scipy/1.4.1-python-3.7.7',
        'pysam/0.16.0.1-python-3.7.7'
    params:
        exe = config.get('monovar', {}).get('exe', '')
    shell:
        'python {params.exe} -i {input.pileup} -s {input.samples} -o {output} '
        '-m {threads}'


# ------------------------------- MRBAYES --------------------------------------

if not scheduler:
    rule run_mrbayes:
        input:
            os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.{steps}.{model}')
        output:
            os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.{steps}.{model}.lstat')
        params:
            mb_exe = config['mrbayes']['exe']
        resources:
            mem_mb = 16384
        shell:
            'cd {out_dir} && '
            '{params.mb_exe} nxs_dir/nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model} '
            '> nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model}.log && '
            'mv nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model}.* nxs_dir'
else:
    rule run_mrbayes_hpc:
        input:
            os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.{steps}.{model}')
        output:
            os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.{steps}.{model}.lstat')
        conda:
            'envs/mrbayes.yaml'
        envmodules:
            'gcc/6.4.0',
            'openmpi/2.1.1',
            'mrbayes/3.2.7'
        threads: 4
        resources:
            mem_mb = 4096 if scheduler == 'lsf' else 3 * 4096,
            runtime = lambda wildcards: get_mrbayes_hpc_runtime(wildcards.steps),
        shell:
            'cd {out_dir} && '
            'mpirun mb nxs_dir/nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model} '
            '> nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model}.log && '
            'mv nxs.{wildcards.run}.{wildcards.steps}.{wildcards.model}.* nxs_dir'


rule merge_mrbayes_results:
    input:
        expand(os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.{steps}.{model}.lstat'),
            run=RUNS, steps=config['mrbayes']['ngen'], model=MODELS)
    output:
        os.path.join(out_dir, 'mrbayes.clock_test_summary.tsv')
    resources:
        mem_mb=2048
    params:
        ss = '-ss' if config.get('mrbayes', {}).get('ss', False) else '',
    shell:
        'python utils.py {input} -f bayes -o {output} {params.ss}'


# -------------------------------- PAUP ----------------------------------------

rule run_PAUP:
    input:
        os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.0.{model}')
    output:
        os.path.join(out_dir, 'nxs_dir', 'nxs.{run}.0.{model}.PAUP.score')
    params:
        paup_exe = config.get('paup', {}).get('exe', 'paup')
    shell:
        '{params.paup_exe} -n {input} > {input}.PAUP.log'


def get_paup_input(wildcards):
    if config.get('paup', {}).get('learn_tree', False):
        models = ['clock']
    else:
        models = MODELS

    in_files = []
    for model in models:
        for run in RUNS:
            in_files.append(os.path.join(out_dir, 'nxs_dir',
                'nxs.{}.0.{}.PAUP.score'.format(run, model)))
    return in_files


rule merge_paup_results:
    input:
        get_paup_input
    output:
        os.path.join(out_dir, 'paup.clock_test_summary.tsv')
    conda:
        'envs/monovar.yaml'
    envmodules:
        'scipy/1.4.1-python-3.7.7',
    resources:
        mem_mb=2048
    params:
        no_cells = config['cellcoal']['model']['no_cells'],
    shell:
        'python utils.py {input} -f LRT -o {output} -nc {params.no_cells} && '
        'tail -n 1 {output}'


# -------------------------------- SCITE ---------------------------------------
rule run_scite:
    input:
        os.path.join(out_dir, 'vcf_dir', 'vcf.{run}')
    output:
        os.path.join(out_dir, 'scite_dir', 'scite_tree.{run}_ml0.newick')
    resources:
        mem_mb=4048
    params:
        steps = config['scite'].get('steps', 1E6),
        exe = config['scite']['exe'],
    run:
        run_scite_subprocess(params.exe, params.steps, input[0])


# -------------------------------- SIEVE ---------------------------------------

rule run_sciphi:
    input:
        pileup = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.mpileup'),
        samples = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleTypes.txt')
    output:
        os.path.join(out_dir, 'sieve_dir', 'sciphi.{run}', 'best_index',
            'readCounts.tsv')
    resources:
        mem_mb=4048
    envmodules:
        'gcccore/6.4.0',
        'boost/1.73.0-python-3.7.7',
        'seqan/2.4.0',
        'dlib/19.16',
        'zlib/1.2.11'
    params:
        sciphi = config['sieve']['sciphi_exe'],
    shell:
        '{params.sciphi} --cwm 2 --slt on --af on --in {input.samples} '
        '-o {out_dir}/sieve_dir/sciphi.{wildcards.run} {input.pileup}'


rule run_sieve_data_collector:
    input:
        read_counts = os.path.join(out_dir, 'sieve_dir', 'sciphi.{run}',
            'best_index', 'readCounts.tsv'),
        samples = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleTypes.txt')
    output:
        os.path.join(out_dir, 'sieve_dir', 'xml.{run}',
            'sieve_template_updated.xml')
    params:
        beast = config['sieve']['beast_bin'],
        xml = config['sieve']['xml']
    shell:
        '{params.beast}/applauncher DataCollectorLauncher -prefix '
        '{out_dir}/sieve_dir/xml.{wildcards.run}/ -cell {input.samples} -sciphi '
        '-data {input.read_counts} -template {params.xml}'


rule get_sieve_final_xml:
    input:
        xml = os.path.join(out_dir, 'sieve_dir', 'xml.{run}',
            'sieve_template_updated.xml'),
        tree = os.path.join(out_dir, 'scite_dir', 'scite_tree.{run}_ml0.newick'),
        samples = os.path.join(out_dir, 'vcf_dir', 'vcf.{run}.SampleTypes.txt')
    output:
        os.path.join(out_dir, 'sieve_dir', 'xml.{run}', 'sieve_{model}.xml')
    params:
        steps = config['sieve']['steps']    
    run:
        get_sieve_xml(input.xml, input.tree, input.samples, wildcards.model,
            params.steps, output[0])


rule run_NS_converter:
    input:
        os.path.join(out_dir, 'sieve_dir', 'xml.{run}', 'sieve_{model}.xml')
    output:
        os.path.join(out_dir, 'sieve_dir', 'data.{run}.{model}',
            'sieve_{model}_NS.xml')
    params:
        beast = config['sieve']['beast_bin'],
    shell:
        '{params.beast}/applauncher MCMC2NS -xml {input} -output {output}'


rule run_sieve:
    input:
        os.path.join(out_dir, 'sieve_dir', 'data.{run}.{model}',
            'sieve_{model}_NS.xml')
    output:
        os.path.join(out_dir, 'sieve_dir', 'data.{run}.{model}',
            'sieve_{model}_final')
    threads: 2
    params:
        beast = config['sieve']['beast_bin'],
    shell:
        '{params.beast}/beast -threads {threads} -prefix '
        '{out_dir}/sieve_dir/sieve.{wildcards.run}.{wildcards.model} {input}'


rule merge_sieve_results:
    input:
        expand(os.path.join(out_dir, 'sieve_dir', 'data.{run}.{model}',
                'sieve_{model}_final'),
            run=RUNS, model=MODELS)
    output:
        os.path.join(out_dir, 'sieve.clock_test_summary.tsv')
    resources:
        mem_mb=2048
    shell:
        'python utils.py {input} -f sieve -o {output}'